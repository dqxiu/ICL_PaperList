
# Paper List for In-context Learning

<!-- omit in toc -->
## Contents

- [Paper List for In-context Learning](#paper-list-for-in-context-learning)
  - [Introduction](#introduction)
    - [Keywords Convention](#keywords-convention)
    - [How to contribute?](#how-to-contribute)
  - [Papers](#papers)
    - [Model Warmup for ICL](#model-warmup-for-icl)
    - [Prompt Tuning for ICL](#prompt-tuning-for-icl)
      - [Prompt Selection Strategies for LLMs](#prompt-selection-strategies-for-llms)
    - [Prompt Formulation Strategies for LLMs](#prompt-formulation-strategies-for-llms)
    - [Analysis of ICL](#analysis-of-icl)
      - [Influence Factors for ICL](#influence-factors-for-icl)
      - [Working Mechanism of ICL](#working-mechanism-of-icl)
    - [Evaluation and Resources](#evaluation-and-resources)
    - [Application](#application)
    - [Problems](#problems)
    - [Challenges and Future Directions](#challenges-and-future-directions)

## Introduction

This is a paper list about **In-context learning**.

### Keywords Convention

![](https://img.shields.io/badge/MetaICL-DCE7F1) abbreviation

![](https://img.shields.io/badge/Analysis-EAD8D9) section in our survey

![](https://img.shields.io/badge/QA-D8D0E1) main feature

![](https://img.shields.io/badge/XXX-FAEFCA) conference

### How to contribute?

- Add new papers to the corresponding part and mark with ![](https://img.shields.io/badge/New-EAD8D9) if the paper has not been included in our survey.
- If the ![](https://img.shields.io/badge/New-EAD8D9) paper is included in the survey, please replace the ![](https://img.shields.io/badge/New-EAD8D9) to the specific section. e.g., ![](https://img.shields.io/badge/Analysis-EAD8D9), and add other basic info about this paper, such as authors, conference.
- If you think the paper does not belong in your section, please move it to another section with the ![](https://img.shields.io/badge/New-EAD8D9) tag.
- **Recent todo: 
  - I will add the paper link, project link, date, conference for all the paper (except the new papers), please renew the ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>) for each paper belongs to your section.
  - Since there is a section title, why should we renew ![](https://img.shields.io/badge/section-EAD8D9)? This is for you to check and make sure that the paper is already added in your section.
  - As there's no paper for intro, lei please add the basic info for all the ![](https://img.shields.io/badge/New-EAD8D9) papers, but please retain the ![](https://img.shields.io/badge/New-EAD8D9) tag, rather than replace it with the ![](https://img.shields.io/badge/XXXSection-EAD8D9).


## Papers

### Model Warmup for ICL

This section contains the pilot works that might contributes to the warmup strategies of ICL.

1. **MetaICL: Learning to Learn In Context NAACL 2022 a pretrained language model is tuned to do in-context learning on a large set of training tasks**. ![](https://img.shields.io/badge/MetaICL-DCE7F1)
   *Sewon Min, Mike Lewis, Luke Zettlemoyer, Hannaneh Hajishirzi*.  [[pdf](https://arxiv.org/abs/2110.15943)], [[project](https://github.com/facebookresearch/metaicl)], 2021.10, ![](https://img.shields.io/badge/NAACL2022-FAEFCA)
    ![](https://img.shields.io/badge/Warmup-EAD8D9) ![](https://img.shields.io/badge/MetaTraining-D8D0E1) 
2. **Improving In-Context Few-Shot Learning via Self-Supervised Training**. ![](https://img.shields.io/badge/MetaICL-DCE7F1)
   *Mingda Chen, Jingfei Du, Ramakanth Pasunuru, Todor Mihaylov, Srini Iyer, Veselin Stoyanov, Zornitsa Kozareva*.  [[pdf](https://aclanthology.org/2022.naacl-main.260.pdf)], [[project]()], 2022.5, ![](https://img.shields.io/badge/NAACL2022-FAEFCA)
    ![](https://img.shields.io/badge/Warmup-EAD8D9) ![](https://img.shields.io/badge/Self_Supervised_Training-D8D0E1)
3. **Calibrate Before Use: Improving Few-shot Performance of Language Models**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](http://proceedings.mlr.press/v139/zhao21c.html)], [[project](https://github.com/tonyzhaozh/few-shot-learning)], 2021.2, ![](<<https://img.shields.io/badge/ICML2021-FAEFCA>)
    ![](https://img.shields.io/badge/Warmup-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
    - Using N/A string to calibrate LMs away from common token bias

### Prompt Tuning for ICL

This section contains the pilot works that might contributes to the prompt selection and prompt formulation strategies of ICL.

#### Prompt Selection Strategies for LLMs
### Prompt Formulation Strategies for LLMs

1. **On the Effect of Pretraining Corpora on In-context Learning by a Large-scale Language Model**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
    - how in-context learning performance changes as the training corpus varies, investigate the effects of the source and size of the pretraining corpus on in-context learning
2. **Chain of Thought Prompting Elicits Reasoning in Large Language Models**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
3. **Least-to-Most Prompting Enables Complex Reasoning in Large Language Models**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
4. **Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator**. . ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
5. **Iteratively Prompt Pre-trained Language Models for Chain of Thought**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
   - uses counterfactual prompting to develop a deeper understanding of CoT(chain of thoughts)-based few-shot prompting mechanisms in large language models. identify and define the key components of a prompt: symbols, patterns, and text
6. **Automatic Chain of Thought Prompting in Large Language Models**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
7. **Learning To Retrieve Prompts for In-Context Learning NAACL 2022 Learn an example retriever via contrastive learning**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
8. **Finetuned Language Models Are Zero-Shot Learners instruction tuning**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
   - finetuning language models on a collection of tasks described via instructions 
   - substantially improves zero-shot performance on unseen tasks
9. **Active Example Selection for In-Context Learning**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
10. **Prompting GPT-3 To Be Reliable establish simple and effective prompts to demonstrate GPT-3's reliability in these four aspects**![](https://img.shields.io/badge/New-EAD8D9)
11. **An lnformation-theoretic Approach to Prompt Engineering Without Ground Truth Labels** （![](https://img.shields.io/badge/New-EAD8D9)
12. **Self-adaptive In-context Learning** ![](https://img.shields.io/badge/New-EAD8D9)
13. **Demystifying Prompts in Language Models via Perplexity Estimation** ![](https://img.shields.io/badge/New-EAD8D9)
14. **Structured Prompting: Scaling In-Context Learning to 1,000 Examples** ![](https://img.shields.io/badge/New-EAD8D9)
<https://arxiv.org/pdf/2212.06713.pdf>


### Analysis of ICL

This section contains the pilot works that might contributes to the influence factors and working mechanism analysis of ICL.

#### Influence Factors for ICL
#### Working Mechanism of ICL

1. **An Explanation of In-context Learning as Implicit Bayesian Inference**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
2. **Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
3. **What Makes Good In-Context Examples for GPT-3?**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
4. **Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
5. **In-context Learning and Induction Heads**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
6. **On the Relation between Sensitivity and Accuracy in In-context Learning**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
7. **What Can Transformers Learn In-Context? A Case Study of Simple Function Classes**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
8. **Emergent Abilities of Large Language Models, Transactions on Machine Learning Research**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
9. **Shivam Garg; Dimitris Tsipras; Percy Liang; Gregory Valiant;  "What Can Transformers Learn In-Context? A Case Study of Simple Function Classes"**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
10. **Stephanie Chan; Adam Santoro; Andrew Lampinen; Jane Wang; Aaditya Singh; Pierre Richemond; James McClelland; Felix Hill;  "Data Distributional Properties Drive Emergent In-Context Learning in Transformers"**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
11. **What learning algorithm is in-context learning? Investigations with linear models**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
12. **Ground-Truth Labels Matter: A Deeper Look into Input-Label Demonstrations** ![](https://img.shields.io/badge/New-EAD8D9)
13. **Can Large Language Models Truly Understand Prompts? A Case Study with Negated Prompts** ![](https://img.shields.io/badge/New-EAD8D9)
14.**Does GPT-3 Generate Empathetic Dialogues? A Novel In-Context Example Selection Method and Automatic Evaluation Metric for Empathetic Dialogue Generation**![](https://img.shields.io/badge/New-EAD8D9)
1.  **Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters** ![](https://img.shields.io/badge/New-EAD8D9)
2.  **Transformers learn in-context by gradient descent∗** <https://export.arxiv.org/pdf/2212.07677>![](https://img.shields.io/badge/New-EAD8D9)
3.  **Can language models learn from explanations in context?** ![](https://img.shields.io/badge/New-EAD8D9)


### Evaluation and Resources

This section contains the pilot works that might contributes to the evaluation or resources of ICL.

1. **Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models**. ![](https://img.shields.io/badge/BigBench-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
2. **SUPER-NATURALINSTRUCTIONS: Generalization via Declarative Instructions on 1600+ NLP Task**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
3. **Language Models are Multilingual Chain-of-Thought Reasoners**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
   - evaluate the reasoning abilities of large language models in multilingual settings, introduce the Multilingual Grade School Math (MGSM) benchmark, by manually translating 250 grade-school math problems from the GSM8K dataset into ten typologically diverse languages.
4. **Instruction Induction: From Few Examples to Natural Language Task Descriptions**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
   - how to learn task instructions from input output demonstrations
5. **Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought**2022.10.3  ![](https://img.shields.io/badge/New-EAD8D9)
6. **What is Not in the Context? Evaluation of Few-shot Learners with Informative Demonstrations** 2212.01692.pdf (arxiv.org)  ![](https://img.shields.io/badge/New-EAD8D9)



### Application

This section contains the pilot works that expands the application of ICL.

1. **Meta-learning via Language Model In-context Tuning**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
2. **Does GPT-3 Generate Empathetic Dialogues? A Novel In-Context Example Selection Method and Automatic Evaluation Metric for Empathetic Dialogue Generation**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf](link)], [[project](link)], 202X.XX, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/feature-D8D0E1>)
3. **In-context Learning Distillation: Transferring Few-shot Learning Ability of Pre-trained Language Models**. ![](https://img.shields.io/badge/Abbre-DCE7F1)
   *authors*.  [[pdf]([link](https://arxiv.org/abs/2212.10670))], [[project](link)], 2022.12, ![](https://img.shields.io/badge/conference-FAEFCA)
    ![](https://img.shields.io/badge/section-EAD8D9) ![](<<https://img.shields.io/badge/distillation-D8D0E1>)
4. **In-context Learning Distillation: Transferring Few-shot Learning Ability of Pre-trained Language Models** ![](https://img.shields.io/badge/New-EAD8D9)
5. **Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions**![](https://img.shields.io/badge/New-EAD8D9)

### Problems

This section contains the pilot works that points out the problems of ICL.

1. **The Inductive Bias of In-Context Learning: Rethinking Pretraining Example Design** ![](https://img.shields.io/badge/New-EAD8D9)


### Challenges and Future Directions

This section contains the pilot works that might contributes to the challenges and future directions of ICL.

