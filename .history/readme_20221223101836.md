
# Paper Notes on Pretrain Language Models with Factual Knowledge

<!-- omit in toc -->
## Contents

- [Paper Notes on Pretrain Language Models with Factual Knowledge](#paper-notes-on-pretrain-language-models-with-factual-knowledge)
  - [Introduction](#introduction)
    - [Keywords Convention](#keywords-convention)
    - [How to contribute?](#how-to-contribute)
  - [Papers](#papers)
    - [Model Warmup for ICL](#model-warmup-for-icl)
    - [Prompt Tuning for ICL](#prompt-tuning-for-icl)
      - [Prompt Selection Strategies for LLMs](#prompt-selection-strategies-for-llms)
    - [Prompt Formulation Strategies for LLMs](#prompt-formulation-strategies-for-llms)
    - [Analysis of ICL](#analysis-of-icl)
      - [Influence Factors for ICL](#influence-factors-for-icl)
      - [Working Mechanism of ICL](#working-mechanism-of-icl)
    - [Evaluation and Resources](#evaluation-and-resources)
    - [Application](#application)
    - [Problems](#problems)
    - [Challenges and Future Directions](#challenges-and-future-directions)

## Introduction

This is a paper list about **In-context learning**.

### Keywords Convention

![](https://img.shields.io/badge/MetaICL-DCE7F1) abbreviation

![](https://img.shields.io/badge/Analysis-EAD8D9) section in our survey

![](https://img.shields.io/badge/QA-D8D0E1) main feature

![](https://img.shields.io/badge/XXX-FAEFCA) conference

### How to contribute?

- Add new papers to the corresponding part and mark with ![](https://img.shields.io/badge/New-EAD8D9) if the paper has not been included in our survey.
- If the ![](https://img.shields.io/badge/New-EAD8D9) paper is included in the survey, please replace the ![](https://img.shields.io/badge/New-EAD8D9) to the specific section. e.g., ![](https://img.shields.io/badge/Analysis-EAD8D9), and add other basic info about this paper, such as authors, conference.
- If you think the paper does not belong in your section, please move it to another section with the ![](https://img.shields.io/badge/New-EAD8D9) tag.


## Papers

### Model Warmup for ICL

This section contains the pilot works that might contributes to the warmup strategies of ICL.

1. **MetaICL: Learning to Learn In Context NAACL 2022 a pretrained language model is tuned to do in-context learning on a large set of training tasks**. ![](https://img.shields.io/badge/MetaICL-DCE7F1)
   *Sewon Min, Mike Lewis, Luke Zettlemoyer, Hannaneh Hajishirzi*.  [[pdf](https://arxiv.org/abs/2110.15943)], [[project](https://github.com/facebookresearch/metaicl)], 2021.10, ![](https://img.shields.io/badge/NAACL2022-FAEFCA)
    ![](https://img.shields.io/badge/Warmup-EAD8D9) ![](https://img.shields.io/badge/MetaTraining-D8D0E1) 
2. **Improving In-Context Few-Shot Learning via Self-Supervised Training**. ![](https://img.shields.io/badge/MetaICL-DCE7F1)
   *Sewon Min, Mike Lewis, Luke Zettlemoyer, Hannaneh Hajishirzi*.  [[pdf](https://arxiv.org/abs/2110.15943)], [[project](https://github.com/facebookresearch/metaicl)], 2021.10, ![](https://img.shields.io/badge/NAACL2022-FAEFCA)
    ![](https://img.shields.io/badge/Warmup-EAD8D9) ![](https://img.shields.io/badge/MetaTraining-D8D0E1)
3. **Calibrate Before Use: Improving Few-shot Performance of Language Models ICML 2021 Using N/A string to calibrate LMs away from common token bias**

### Prompt Tuning for ICL

This section contains the pilot works that might contributes to the prompt selection and prompt formulation strategies of ICL.

#### Prompt Selection Strategies for LLMs
### Prompt Formulation Strategies for LLMs

1. **On the Effect of Pretraining Corpora on In-context Learning by a Large-scale Language Model NAACL 2022 how in-context learning performance changes as the training corpus varies, investigate the effects of the source and size of the pretraining corpus on in-context learning**
2. **Chain of Thought Prompting Elicits Reasoning in Large Language Models**
3. **Least-to-Most Prompting Enables Complex Reasoning in Large Language Models**
4. **Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator**. ![](https://img.shields.io/badge/MetaICL-DCE7F1)
*Hyuhng Joon Kim, Hyunsoo Cho, Junyeob Kim, Taeuk Kim, Kang Min Yoo, Sang-goo Lee*.  [[pdf](https://arxiv.org/pdf/2206.08082.pdf)], [[project]()], 2021.10, ![](https://img.shields.io/badge/SG-ICL-FAEFCA)
    ![](https://img.shields.io/badge/prompt-EAD8D9) ![](https://img.shields.io/badge/self-generated-prompt-D8D0E1)
1. **Iteratively Prompt Pre-trained Language Models for Chain of Thought**
   - uses counterfactual prompting to develop a deeper understanding of CoT(chain of thoughts)-based few-shot prompting mechanisms in large language models. identify and define the key components of a prompt: symbols, patterns, and text
2. **Automatic Chain of Thought Prompting in Large Language Models**
3. **Learning To Retrieve Prompts for In-Context Learning NAACL 2022 Learn an example retriever via contrastive learning**
4. **Finetuned Language Models Are Zero-Shot Learners instruction tuning**
   - finetuning language models on a collection of tasks described via instructions 
   - substantially improves zero-shot performance on unseen tasks
5. **Active Example Selection for In-Context Learning**,  <https://arxiv.org/abs/2211.04486> ARXIV,  2022.
    *Yiming Zhang, Shi Feng, Chenhao Tan* 
6.  **Prompting GPT-3 To Be Reliable establish simple and effective prompts to demonstrate GPT-3's reliability in these four aspects**![](https://img.shields.io/badge/New-EAD8D9)
7.  **An lnformation-theoretic Approach to Prompt Engineering Without Ground Truth Labels** （![](https://img.shields.io/badge/New-EAD8D9)
8.  ****<https://arxiv.org/abs/2212.10375> ![](https://img.shields.io/badge/New-EAD8D9)
9.  **Demystifying Prompts in Language Models via Perplexity Estimation** ![](https://img.shields.io/badge/New-EAD8D9)
10. **Structured Prompting: Scaling In-Context Learning to 1,000 Examples** ![](https://img.shields.io/badge/New-EAD8D9)
<https://arxiv.org/pdf/2212.06713.pdf>


### Analysis of ICL

This section contains the pilot works that might contributes to the influence factors and working mechanism analysis of ICL.

#### Influence Factors for ICL
#### Working Mechanism of ICL

1. **An Explanation of In-context Learning as Implicit Bayesian Inference** ICLR 2022
2. **Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?** EMNLP 2022 (long).
3. **What Makes Good In-Context Examples for GPT-3?**  
4. **Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity** ACL 2021
5. **In-context Learning and Induction Heads**
6. **On the Relation between Sensitivity and Accuracy in In-context Learning** 2022.9.16
7. **What Can Transformers Learn In-Context? A Case Study of Simple Function Classes** 2022.8.14
8. **Emergent Abilities of Large Language Models, Transactions on Machine Learning Research** (TMLR), 2022
9. **Shivam Garg; Dimitris Tsipras; Percy Liang; Gregory Valiant;  "What Can Transformers Learn In-Context? A Case Study of Simple Function Classes"**,   ARXIV,  2022.
10. **Stephanie Chan; Adam Santoro; Andrew Lampinen; Jane Wang; Aaditya Singh; Pierre Richemond; James McClelland; Felix Hill;  "Data Distributional Properties Drive Emergent In-Context Learning in Transformers"**,   NIPS,  2022.
11. **WHAT LEARNING ALGORITHM IS IN-CONTEXT LEARNING? INVESTIGATIONS WITH LINEAR MODELS** (ICLR 2023, 8-8-8)
12. **Ground-Truth Labels Matter: A Deeper Look into Input-Label Demonstrations** ![](https://img.shields.io/badge/New-EAD8D9)
13. **Can Large Language Models Truly Understand Prompts? A Case Study with Negated Prompts** ![](https://img.shields.io/badge/New-EAD8D9)
14.**Does GPT-3 Generate Empathetic Dialogues? A Novel In-Context Example Selection Method and Automatic Evaluation Metric for Empathetic Dialogue Generation** COLING ![](https://img.shields.io/badge/New-EAD8D9)
15. **Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters** ![](https://img.shields.io/badge/New-EAD8D9)
16. **Transformers learn in-context by gradient descent∗** <https://export.arxiv.org/pdf/2212.07677>![](https://img.shields.io/badge/New-EAD8D9)
17. **Can language models learn from explanations in context?** ![](https://img.shields.io/badge/New-EAD8D9)


### Evaluation and Resources

This section contains the pilot works that might contributes to the evaluation or resources of ICL.

1. **Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models** Big-Bench
2. **SUPER-NATURALINSTRUCTIONS: Generalization via Declarative Instructions on 1600+ NLP Task** EMNLP 2022
3. **Language Models are Multilingual Chain-of-Thought Reasoners**
   - evaluate the reasoning abilities of large language models in multilingual settings, introduce the Multilingual Grade School Math (MGSM) benchmark, by manually translating 250 grade-school math problems from the GSM8K dataset into ten typologically diverse languages.
4. **Instruction Induction: From Few Examples to Natural Language Task Descriptions**
   - how to learn task instructions from input output demonstrations
5. **Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought**2022.10.3  ![](https://img.shields.io/badge/New-EAD8D9)
6. **What is Not in the Context? Evaluation of Few-shot Learners with Informative Demonstrations** 2212.01692.pdf (arxiv.org)  ![](https://img.shields.io/badge/New-EAD8D9)



### Application

This section contains the pilot works that expands the application of ICL.

1. **Meta-learning via Language Model In-context Tuning** ACL 2022
2. **Does GPT-3 Generate Empathetic Dialogues? A Novel In-Context Example Selection Method and Automatic Evaluation Metric for Empathetic Dialogue Generation** COLING 2022
3. **arXiv:2212.10670** [pdf, other]
4. **In-context Learning Distillation: Transferring Few-shot Learning Ability of Pre-trained Language Models** ![](https://img.shields.io/badge/New-EAD8D9)
5. **Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions**![](https://img.shields.io/badge/New-EAD8D9)

### Problems

This section contains the pilot works that points out the problems of ICL.

1. **The Inductive Bias of In-Context Learning: Rethinking Pretraining Example Design** ![](https://img.shields.io/badge/New-EAD8D9)


### Challenges and Future Directions

This section contains the pilot works that might contributes to the challenges and future directions of ICL.




