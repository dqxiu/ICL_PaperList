
# Paper Notes on Pretrain Language Models with Factual Knowledge

<!-- omit in toc -->
## Contents

- [Paper Notes on Pretrain Language Models with Factual Knowledge](#paper-notes-on-pretrain-language-models-with-factual-knowledge)
  - [Introduction](#introduction)
    - [Keywords Convention](#keywords-convention)
    - [How to contribute?](#how-to-contribute)
  - [Papers](#papers)
    - [Model Warmup for ICL](#model-warmup-for-icl)
    - [Prompt Tuning for ICL](#prompt-tuning-for-icl)
      - [Prompt Selection Strategies for LLMs](#prompt-selection-strategies-for-llms)
    - [Prompt Formulation Strategies for LLMs](#prompt-formulation-strategies-for-llms)
    - [Analysis of ICL](#analysis-of-icl)
      - [Influence Factors for ICL](#influence-factors-for-icl)
      - [Working Mechanism of ICL](#working-mechanism-of-icl)
    - [Evaluation and Resources](#evaluation-and-resources)
    - [Application](#application)
    - [Challenges and Future Directions](#challenges-and-future-directions)
    - [Continual Pretraining](#continual-pretraining)
    - [Model Editing v.s. Continual Learning](#model-editing-vs-continual-learning)

## Introduction

This is a paper list about **In-context learning**.

### Keywords Convention

![](https://img.shields.io/badge/MetaICL-DCE7F1) abbreviation

![](https://img.shields.io/badge/Analysis-EAD8D9) section in our survey

![](https://img.shields.io/badge/QA-D8D0E1) main task

![](https://img.shields.io/badge/20220331-FAEFCA) editing info

### How to contribute?

- Add new papers to the corresponding part and mark with ![](https://img.shields.io/badge/New-EAD8D9) if the paper has not been included in our survey.
- If the ![](https://img.shields.io/badge/New-EAD8D9) paper is included in the survey, please replace the ![](https://img.shields.io/badge/New-EAD8D9) to the specific section. e.g., ![](https://img.shields.io/badge/Analysis-EAD8D9).
- If you think the paper does not belong in your section, please move it to another section with the ![](https://img.shields.io/badge/New-EAD8D9) tag.


## Papers

### Model Warmup for ICL

 1. A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models [[pdf](https://arxiv.org/pdf/2202.08772.pdf)]
 
 summarize the current progress of pre-trained language model based knowledge-enhanced models (PLMKEs) by dissecting their three vital elements: knowledge sources, knowledge-intensive NLP tasks, and
 knowledge fusion methods.
 main encyclopedic knowledge-intensive NLP tasks:
 - Open-domain QA
   - Natural Questions
   - HotpotQA
 - Fact Verification
   - FEVER
   - BOOLQ
 - Entity Linking
   - ACE2004
   - AIDA CoNLL-YAGO
   - WNWI
   - WNCW

### Prompt Tuning for ICL
#### Prompt Selection Strategies for LLMs
### Prompt Formulation Strategies for LLMs

### Analysis of ICL
#### Influence Factors for ICL
#### Working Mechanism of ICL

1. An Explanation of In-context Learning as Implicit Bayesian Inference ICLR 2022
2. Rethinking the Role of Demonstrations: What Makes In-Context Learning Work? EMNLP 2022 (long).
3. What Makes Good In-Context Examples for GPT-3?  
4. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity ACL 2021
5. In-context Learning and Induction Heads
6. On the Relation between Sensitivity and Accuracy in In-context Learning 2022.9.16
7. What Can Transformers Learn In-Context? A Case Study of Simple Function Classes 2022.8.14
8. Emergent Abilities of Large Language Models, Transactions on Machine Learning Research (TMLR), 2022
9. Shivam Garg; Dimitris Tsipras; Percy Liang; Gregory Valiant;  "What Can Transformers Learn In-Context? A Case Study of Simple Function Classes",   ARXIV,  2022.
10. Stephanie Chan; Adam Santoro; Andrew Lampinen; Jane Wang; Aaditya Singh; Pierre Richemond; James McClelland; Felix Hill;  "Data Distributional Properties Drive Emergent In-Context Learning in Transformers",   NIPS,  2022.
11. WHAT LEARNING ALGORITHM IS IN-CONTEXT LEARNING? INVESTIGATIONS WITH LINEAR MODELS (ICLR 2023, 8-8-8)
12. Ground-Truth Labels Matter: A Deeper Look into Input-Label Demonstrations ![](https://img.shields.io/badge/New-EAD8D9)
13. Can Large Language Models Truly Understand Prompts? A Case Study with Negated Prompts ![](https://img.shields.io/badge/New-EAD8D9)
14. Does GPT-3 Generate Empathetic Dialogues? A Novel In-Context Example Selection Method and Automatic Evaluation Metric for Empathetic Dialogue Generation COLING ![](https://img.shields.io/badge/New-EAD8D9)
15. Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters ![](https://img.shields.io/badge/New-EAD8D9)
16. <https://export.arxiv.org/pdf/2212.07677> ![](https://img.shields.io/badge/New-EAD8D9)
17. Can language models learn from explanations in context? ![](https://img.shields.io/badge/New-EAD8D9)


### Evaluation and Resources



### Application

1. Meta-learning via Language Model In-context Tuning ACL 2022
2. Does GPT-3 Generate Empathetic Dialogues? A Novel In-Context Example Selection Method and Automatic Evaluation Metric for Empathetic Dialogue Generation COLING 2022
3. arXiv:2212.10670 [pdf, other]
In-context Learning Distillation: Transferring Few-shot Learning Ability of Pre-trained Language Models
.application: arxiv.org/abs/2212.10509


### Challenges and Future Directions

This section contains the pilot works that might contributes to the prevalence of model editiing paradigm.

1. **Editable Neural Networks** ICLR 2020. ![](https://img.shields.io/badge/Editable_training-DCE7F1)

   *Anton Sinitsin, Vsevolod Plokhotnyuk, Dmitriy Pyrkin, Sergei Popov, Artem Babenko*.  [[pdf](https://openreview.net/pdf?id=HJedXaEtvS)], [[project](https://github.com/xtinkt/editable)],  2020.7
   ![](https://img.shields.io/badge/image_classification-D8D0E1) ![](https://img.shields.io/badge/machine_translation-D8D0E1)

   Related work:
   - re-train on the original dataset augmented with new samples (expensive)
   - use a manual cache (e.g. lookup table) that overrules model predictions on problematic samples (can't generalize to semantic equivalent inputs)
   Method:
   Editable Training (employ meta-learning techniques to ensure that mistakes can be corrected without harming its overall performance)
   <!-- ![Alt text-w15](editable_train.png) -->

   <img src="img/editable_train.png" width="800" alt="webhooks">

2. **Fact-based Text Editing** ACL 2020. ![](https://img.shields.io/badge/Fact_based_text_editing-DCE7F1)

   *Hayate Iso, Chao Qiao, Hang Li*.  [[pdf](https://aclanthology.org/2020.acl-main.17.pdf)], [[project](https://github.com/isomap/factedit)],  2020.7
   ![](https://img.shields.io/badge/edit_draft_text_editing-D8D0E1)

   Main cons.:
   - propose a new dataset (task): transforms a draft text into a revised text based on given triples
   - new model, FACTEDITOR. The model consists of three components, a buffer for storing the draft text and its representations, a stream for storing the revised text and its representations, and a memory for storing the triples and their representations
   <!-- ![Alt text-w15](editable_train.png) -->

   <img src="img/fte.png" width="300" alt="webhooks">

2. Modifying Memories in Transformer Models
   Explicitly modifying specific factual knowledge in Transformer models while ensuring the model performance does not degrade on the unmodified facts.
    - Motivation
  - updating stale knowledge
  - protecting privacy
  - eliminating unintended biases (debias)
   - Baseline
  - Retraining the model on modified training set
  - Fine-tuning on modified facts
  - Fine-tuning on a mixture of modified and unmodified batches
 - Method
     - Constrained fine-tuning on supporting evidences for modified facts

3. Editing Factual Knowledge in Language Models
    - Evaluation
  - success rate: updates the knowledge
  - retain accuracy: retains the original predictions
  - equivalence accuracy: for semantically equivalent inputs,
  - performance deterioration: test performance deteriorates

4. Fast Model Editing at Scale
    a model editor efficient: if the time and memory requirements for computing Ï† and evaluating E are small.
gradients are highdimensional objects ðŸ‘‰ using a low-rank decomposition of the gradient

5. Locating and Editing Factual Knowledge in GPT (preprint)

### Continual Pretraining

1. Don't Stop Pretraining: Adapt Language Models to Domains and Tasks (ACL 2020)
2. Mind the Gap: Assessing Temporal Generalization in Neural Language Models (NeurIps 2021)
3. Towards Continual Knowledge Learning of Language Models (preprint)
4. DEMix Layers: Disentangling Domains for Modular Language Modeling (preprint)
5. Lifelong Pretraining: Continually Adapting Language Models to Emerging Corpora (preprint)
6. Time-Aware Language Models as Temporal Knowledge Bases (preprint)
7. Dynamic Language Models for Continuously Evolving Content (KDD 2021)
8. ELLE: Efficient Lifelong Pre-training for Emerging Data (Findings of ACL 2022)

### Model Editing v.s. Continual Learning

- Common: assimilating or updating a modelâ€™s behavior without catastrophic forgetting

- Continual learning: learn a new task while preserving the performance on the previous tasks
wholly new behaviors or datasets
long sequences of model updates

- Model editing: explicitly modifying specific factual knowledge in models while ensuring the model performance does not degrade on the unmodified facts
considers an edit or batch of edits applied all at once
requires the model to memorize new facts that conflict with previously learned facts
